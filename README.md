# Gradient Descent Algorithm Comparison

This repository contains two Jupyter Notebook files (`part1.ipynb` and `part2.ipynb`) that demonstrate the implementation and comparison of the Gradient Descent algorithm. 

## Table of Contents

- [Introduction](#introduction)
- [Implementation](#implementation)
- [Usage](#usage)
- [Results](#results)
- [Conclusion](#conclusion)

## Introduction

The Gradient Descent algorithm is a popular optimization algorithm used in machine learning and mathematical optimization. It aims to minimize a given cost function by iteratively adjusting the model parameters.

In this project, we compare two implementations of the Gradient Descent algorithm:
1. `part1.ipynb`: Implementation from scratch without using any external libraries.
2. `part2.ipynb`: Implementation using popular libraries such as NumPy and scikit-learn.

## Implementation

- `part1.ipynb`: This notebook contains the implementation of the Gradient Descent algorithm from scratch. It includes the necessary mathematical formulas and step-by-step code explanations.

- `part2.ipynb`: This notebook demonstrates the same Gradient Descent algorithm but implemented using libraries such as NumPy and scikit-learn. It provides a comparison between the custom implementation and the library implementation in terms of code simplicity and performance.

## Usage

To run the notebooks, make sure you have Jupyter Notebook installed. You can install it using the following command:

